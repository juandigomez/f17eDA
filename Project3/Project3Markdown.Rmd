---
title: "Project 3: Prediction of 2016 Election"
author: "Group 8: Jackie Lee, Juan Gomez, Patrick Lyons, Ross Miglin"
resource_files:
- .Renviron
output:
  html_notebook:
    code_folding: hide
    toc: yes
    toc_depth: 8
    toc_float: yes
runtime: shiny
---

```{r setup, include=FALSE}
require(data.world)
require(MASS)
require(ISLR)
require(dplyr)
require(ggplot2)
require(hexbin)
require(jsonlite)
require(shiny)
require(rsconnect)
require(knitr)
require(lubridate)
require(rmarkdown)
require(tidyr)
library(rsconnect)
library(class)
knitr::opts_chunk$set(echo = TRUE)
```

## **R Session Info**
```{r}
sessionInfo()
```

## **Introduction**
In order to analyze the methods discussed in class for model comparison, we decided to use data on the 2016 Presidential Election in order to make predictions of which candidate one based on different races and different occupations. This is especially interesting because we now know what factors where key in the success Trump. So we can make models and assumptions based on that information to see if these factors are as significant in our models as the were in real life.


## **Requiring data and initializing session**
We have retrieved our data and required the proper libraries in order to correctly compute our analysis. Our data can be viewed at https://data.world/juandi/f-17-edaproject-3.
```{r}
require(data.world)

project <- "https://data.world/juandi/f-17-edaproject-3"

df <- data.world::query(
  data.world::qry_sql("SELECT * FROM electiondata"),
  dataset = project
)

attach(df)
library(class)
library(glmnet)
library(leaps)
```

## **Simple and Multiple Linear Regressions**

We started our analysis by choosing one or more variables to plot vs. candidates and adding trendlines to those plots. We first focused on how one's occupation might affect their voting preference.

```{r}
#Setting categorical variables to numeric in order to graph output
df$candidate[df$candidate == "Trump"] <- 1
df$candidate[df$candidate == "Clinton"] <- 0
df$candidate = as.numeric(df$candidate)

plot(formula = candidate~management_occup, data=df)
abline(lm(formula=candidate~management_occup, data=df),col="red",lwd=1.5)
fitOccup = lm(forumla=candidate~management_occup, data=df)
fitOccup
summary(fitOccup)
```
Since the dependent variable of our data is binary (1 for Trump, 0 for Clinton), laying a linear regression line on the data doesn't highlight valuable correlation. We graphed the residuals against the fitted data to resolve this issue.
```{r}
#Residuals Plot
fitOccup2 = lm(management_occup~agri_occup+candidate,data=df)
fitOccup2
points(management_occup,fitted(fitOccup2),col="blue",pch=20)
summary(fitOccup2)
plot(fitOccup2)
plot.new
plot.new
plot.new
plot.new
```
Because our R-squared value was still low, we decided to factor in other occupations in addition to management.
```{r}
#Non-linear Plot
fitOccup3 = lm(management_occup~agri_occup*candidate,data=df)
fitOccup3
plot(fitOccup3)
points(management_occup,fitted(fitOccup3),col="blue",pch=20)
summary(fitOccup3)
plot(fitOccup3)
```

## **K-Nearest Neighbors**

One of the methods used to conduct the analysis is K-Nearest Neighbors. Below shows the code and results for the analysis on this method.

First of all, we must set the training data to conduct KNN. We use the votes variable since the amount of votes  per state has no real effect on who won.
```{r}
# Setting training data
train = df$votes > 1000000
```


Our first test using KNN is using the white_pop and unemployment variable to predict a winner. As seen in the election, the white and unemployed voters were one of the demographics that largely voted for Trump.
```{r}
## Test 1: Using the white population percentage and unemployment population percentage

#Binding predictors
test1 = cbind(df$white_pop,df$unemployment)

#Running KNN test
knn.pred1 = knn(test1[train,], test1[!train,], df$candidate[train], k=1)
```

```{r}
#Confusion matrix and mean
table(knn.pred1,df$candidate[!train])
mean(knn.pred1==df$candidate[!train])
```


```{r}
## Test 2: Using the white population percentage and unemployment population percentage
test2 = cbind(df$latino_pop,df$management_occup)

#Running KNN test
knn.pred1 = knn(test2[train,], test2[!train,], df$candidate[train], k=1)

#Confusion matrix and mean
table(knn.pred1,df$candidate[!train])
mean(knn.pred1==df$candidate[!train])
```

## **Linear Discriminant Analysis**
Now, we want to predict the candidate using LDA. In this model, we create a sample for our training set.

```{r}
train2 <- sample(1:50, 25)
candidates2=lda(candidate~graduates_degree+asian_american_pop+bachelors+pct_dem,data=df,prior=c(1,1)/2,subset=train2)
candidates2
renderPlot({plot(candidates2)})
lda.pred2=predict(candidates2, df[-train2, ])
dflda2 = data.frame(lda.pred2)
table(lda.pred2$class,df[-train2, ]$candidate)
mean(lda.pred2$class==df[-train2, ]$candidate)
```

**Interactive Histogram and Boxplot**
```{r}
sliderInput("bins", "Number of bins:", min = 10, max = 50, value = 30)


renderPlot({
  x <- dflda2$LD1
  bins <- seq(min(x), max(x), length.out = input$bins + 1)
  ggplot(dflda2) + geom_histogram(mapping = aes(x=LD1), breaks = bins, color="blue") + facet_wrap(~class)})

renderPlot(ggplot(dflda2) + geom_boxplot(mapping = aes(x=class, y=LD1), color = "blue"))
```

**Using Predictors from Best Subset Regression**
```{r}
candidates3=lda(candidate~pct_rep+less_than_high_school+asian_american_pop+unemployment,data=df,prior=c(1,1)/2,subset=train2)
candidates3
lda.pred3=predict(candidates3, df[-train2, ])
dflda3 = data.frame(lda.pred3)
table(lda.pred3$class,df[-train2, ]$candidate)
mean(lda.pred3$class==df[-train2, ]$candidate)
```
First we ran every single predictor alone through LDA, and then picked the predictors that we believed to be the best at predicting candidate. From there, we ran the LDA model for the four predictors that we picked. Next we wanted to compare the results of our model to the predictors from the best subset regression that are from the KNN analysis. After running those four predictors through the LDA model, we came to the conclusion that the predictors we picked are slightly better at predicting the candidate because of the higher mean accuracy rate from our model. All in all, the LDA model strongly predicts the right candidate.

## **Logistic Regression Analysis**
Here, we used logistic regression to predict the candidate by experimenting with several variables in the dataset.

```{r}
#Exactly as we had to do for the multiple linear regression, here we setting categorical variables to a binary, numeric in order to perform a logistic fit
df$candidate[df$candidate == "Trump"] <- 1
df$candidate[df$candidate == "Clinton"] <- 0
df$candidate = as.numeric(df$candidate)

#we first created a glm.fit using total_population, votes, bachelors, and unemployment to predict candidate
glm.fit <- glm(candidate~total_population+votes+bachelors+unemployment,data=df,family=binomial)
summary(glm.fit)
glm.probs = predict(glm.fit,type="response")
glm.probs[1:5]
glm.pred=ifelse(glm.probs>0.5,1,0) #if it's >0.5, we call it clinton, otherwise trump
attach(df) #allows us to use variables by name
table(glm.pred,candidate) #allows us to compare our predictions to the actual data
mean(glm.pred==candidate) #classification performance: gives us proportion

#creating the logistic regression plot and curve
plot(bachelors,candidate,xlab="Bachelors",ylab="Candidate")
g=glm(candidate~bachelors,data=df,family=binomial)
curve(predict(g,data.frame(bachelors=x),type="resp"),add=TRUE)
points(bachelors,fitted(g),pch=20)
```
Then we experimented with more variables and different combinations of variables to see if we could find better predictors. In this case, we tested just the variable less_than_high_school.
```{r}
glm.fit2 <- glm(candidate~less_than_high_school, data=df,family=binomial)
summary(glm.fit2)
glm.probs2 = predict(glm.fit2,type="response")
glm.probs2[1:5]
glm.pred2=ifelse(glm.probs2>0.5,1,0) #if it's >0.5, we call it clinton, otherwise trump
attach(df) #allows us to use variables by name
table(glm.pred2,candidate) #allows us to compare our predictions to the actual data
mean(glm.pred2==candidate) #classification performance: gives us proportion

#creating the logistic regression plot and curve
plot(less_than_high_school,candidate,xlab="Less Than High School",ylab="Candidate")
g=glm(candidate~less_than_high_school,data=df,family=binomial)
curve(predict(g,data.frame(less_than_high_school=x),type="resp"),add=TRUE)
points(less_than_high_school,fitted(g),pch=20)
```
And finally, we identified the greatest predictor of candidate, graduates_degree, evidenced by the highest mean value.
```{r}
glm.fit3 <- glm(candidate~graduates_degree+less_than_high_school, data=df,family=binomial)
summary(glm.fit3)
glm.probs3 = predict(glm.fit3,type="response")
glm.probs3[1:5]

glm.pred3=ifelse(glm.probs3>0.5,1,0) #if it's >0.5, we call it clinton, otherwise trump
attach(df) #allows us to use variables by name
table(glm.pred3,candidate) #allows us to compare our predictions to the actual data
mean(glm.pred3==candidate) #classification performance: gives us proportion
plot(graduates_degree,candidate,xlab="Graduates Degree",ylab="Candidate")
g=glm(candidate~graduates_degree,data=df,family=binomial)
curve(predict(g,data.frame(graduates_degree=x),type="resp"),add=TRUE)
points(graduates_degree,fitted(g),pch=20)
```

## **Quadratic Discriminant Analysis**
We want to add a little more flexibility to our covariance matrix by extending our model to QDA:

```{r}
qda.fit = qda(candidate~management_occup+service_occup+sales_occup+agri_occup,data=df)
qda.fit

df.33 = subset(df,management_occup>=33)
qda.class = predict(qda.fit, df.33)
table(qda.class$class,df.33$candidate)
mean(qda.class$class==df.33$candidate)
```

## **Interesting Findings**
Our insights can be found here: https://data.world/juandi/f-17-edaproject-3/insights

**LDA Interesting Findings**
In the beginning, we played around with the data and one of the first lda models we ran was with two predictors:bachelors and unemployment. We expected these two predictors to have a strong influence in predicting either Trump or Clinton because we believed people with bachelors would be more inclined to vote for Clinton and that the unemployed would be dissatisfied with the current political status(at the time). The model mean accuracy rate came out to be nearly 80% which confirmed our beliefs. But when we ran each predictor alone through the LDA model, the model mean accuracy rate came out to be 0.48 which is fairly weak. This came as a surprise and we realized that the bachelors variable was the actual factor that led to the high model mean accuracy rate.

The other interesting finding for LDA was for the predictor agri_occup. We believed that agri_occup would strongly predict the right candidate because there was an emphasis during the election that people in the agricultural business were fed up with the government and wanted a change. Surprisingly, the confusion matrix predicted Trump 21 times and out of those 21, 17 actually went to Clinton. We did not expect this and the model mean accuracy rate came out to be around 38%.

**Logistic Regression Interesting Findings**
Our initial linear regression analysis used the variables of bachelors degree, total population, number of votes, and unemployment to try to to predict the outcome of the election. We were surprised to find that out of these, only the presence of a bachelors degree was a significant enough variable to have a strong measure of prediction in the matter. Specifically, I expected unemployment to have a strong correlation, but it did not. After performing the glm.fit and glm.pred, we found quite a high mean in carrying out this prediction of .88, or 88%. This makes linear regression quite a useful tool in making these sorts of predictions for which candidate wins based on this dataset.

In testing other variables to use for logistic regression, we found that the less_than_high_school variable yielded significant correlation to candidate, as shown by probability value. This was not surprising because it makes sense that education level would have a strong connection/correlation to political preference. What was surprising, however, was that the mean value was significantly lower for less_than_high_school than the the mean value for the bachelors variable analyzed in my previous insight (0.72 versus 0.88, respectively). Though surprising, this data certainly was helpful in knowing which variables were most important to consider for further analysis.

After testing every single variable in the dataset, we determined graduates_degree to be the single most correlated variable for a logistic regression analysis of the electiondata dataset. This makes sense because a graduates degree entails having far above the average amount of education of an average American, so we'd expect a strong correlation. Compared to the mean value with less_than_high_school (0.72) and with bachelors (0.88), graduates_degree blows them out of the water with a mean value of 0.92.

**QDA Interesting Findings**
We initially ran QDA expecting to get a higher r-squared value than LDA because QDA has a tighter covariance matrix. This proved to be true. Testing out different occupation variables against candidates returned high r-squared values. And when I created a subsection based on states with individuals in management occupations greater than or equal to 33%, the mean for estimating correctly the candidate they voted for was 93.75% equivalent to guessing correctly 15 of 16 times.