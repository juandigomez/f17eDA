x<-bachelors
#convert data to a data frame
data<-data.frame(y=factor(y),x)
head(data)
Radialsvm=svm(factor(y) ~ .,data=data,kernel="radial",cost=5,scale=F)
Radialsvm
#confusion matrix to check the accuracy
table(predicted=Radialsvm$fitted,actual=data$y)
#misclassification Rate
mean(Radialsvm$fitted!=data$y)*100 #8% misclassification rate
xgrid=expand.grid(X1=px1,X2=px2) #generating grid points
ygrid=predict(Radialsvm,newdata = xgrid)
renderPlot(plot(xgrid,col=as.numeric(ygrid),pch=20,cex=0.3)+points(x,col=y+1,pch=19))
# Chunk 1: setup
require(data.world)
require(MASS)
require(ISLR)
require(dplyr)
require(ggplot2)
require(hexbin)
require(jsonlite)
require(shiny)
require(rsconnect)
require(knitr)
require(lubridate)
require(rmarkdown)
require(tidyr)
require(glmnet)
library(ggplot2)
library(class)
library(glmnet)
library(leaps)
library("e1071")
require(tree)
require(randomForest)
require(gbm)
knitr::opts_chunk$set(echo = TRUE)
# Chunk 2
sessionInfo()
# Chunk 3
require(data.world)
project <- "https://data.world/juandi/f-17-eda-project-4"
data.world::set_config(cfg_env("DW_API"))
electiondf <- data.world::query(
data.world::qry_sql("SELECT * FROM electiondata"),
dataset = project
)
attach(electiondf)
# Chunk 4
# Setting up the data
df = electiondf
result = df$candidate
df$candidate[df$candidate == "Trump"] <- 1
df$candidate[df$candidate == "Clinton"] <- 0
drops <- c("state")
df <- df[ , !(names(df) %in% drops)]
df$candidate = as.numeric(df$candidate)
df$candidate = as.numeric(df$votes)
df=data.frame(df, result)
# Chunk 5
tree.candidate=tree(result~.,df)
summary(tree.candidate)
renderPlot(plot(tree.candidate))
#text(tree.candidate,pretty=0))
# Chunk 6
set.seed(101)
train=sample(1:nrow(df),20)
rf.election=randomForest(result~.-candidate,data=df,subset=train)
rf.election
# Chunk 7
set.seed(101)
train1=sample(1:nrow(df),30)
rf.election1=randomForest(result~.-candidate,data=df,subset=train1)
rf.election1
# Chunk 8
set.seed(101)
train2=sample(1:nrow(df),45)
rf.election2=randomForest(result~.-candidate,data=df,subset=train2)
rf.election2
# Chunk 9
set.seed(101)
train=sample(1:nrow(df),45)
boost.election=gbm(result~.,data=df[train,],distribution="gaussian",n.trees=1000,shrinkage=0.001,interaction.depth=2)
renderPlot(summary(boost.election))
# Chunk 10
boost.election=gbm(result~.,data=df[train,],distribution="gaussian",n.trees=100,shrinkage=1,interaction.depth=3)
renderPlot(summary(boost.election))
# Chunk 11
boost.election=gbm(result~.,data=df[train,],distribution="gaussian",n.trees=10000,shrinkage=0.01,interaction.depth=4)
renderPlot(summary(boost.election))
# Chunk 12
renderPlot(plot(boost.election,i="graduates_degree"))
renderPlot(plot(boost.election,i="asian_american_pop"))
# Chunk 13
grad_deg=c(graduates_degree)
percent_dem=c(pct_dem)
train=data.frame(grad_deg,percent_dem)
model <- lm(percent_dem ~ grad_deg, train)
model_svm <- svm(percent_dem~grad_deg,train)
pred <- predict(model_svm,train)
renderPlot(plot(train,pch=16)+abline(model)+points(train$grad_deg, pred, col="blue", pch=4))
# Chunk 14
error <- model$residuals
lm_error <- sqrt(mean(error^2)) # 3.832974
error_2 <- train$percent_dem - pred
svm_error <- sqrt(mean(error_2^2)) # 2.696281
svm_tune <- tune(svm, percent_dem ~ grad_deg, data = train,
ranges = list(epsilon = seq(0,1,0.01), cost = 2^(2:9))
)
renderPlot(plot(bachelors,col=candidate+3))
y<-candidate
x<-bachelors
#convert data to a data frame
data<-data.frame(y=factor(y),x)
head(data)
Radialsvm=svm(factor(y) ~ .,data=data,kernel="radial",cost=5,scale=F)
Radialsvm
#confusion matrix to check the accuracy
table(predicted=Radialsvm$fitted,actual=data$y)
#misclassification Rate
mean(Radialsvm$fitted!=data$y)*100 #8% misclassification rate
xgrid=expand.grid(X1=px1,X2=px2) #generating grid points
ygrid=predict(Radialsvm,newdata = xgrid)
renderPlot(plot(xgrid,col=as.numeric(ygrid),pch=20,cex=0.3)+points(x,col=y+1,pch=19))
renderPlot(plot(bachelors,col=candidate+3))
y<-candidate
x<-bachelors
#convert data to a data frame
data<-data.frame(y=factor(y),x)
head(data)
Radialsvm=svm(factor(y) ~ .,data=data,kernel="radial",cost=5,scale=F)
Radialsvm
#confusion matrix to check the accuracy
table(predicted=Radialsvm$fitted,actual=data$y)
#misclassification Rate
mean(Radialsvm$fitted!=data$y)*100 #8% misclassification rate
xgrid=expand.grid(X1=px1,X2=px2) #generating grid points
ygrid=predict(Radialsvm,newdata = xgrid)
renderPlot(plot(xgrid,col=as.numeric(ygrid),pch=20,cex=0.3)+points(x,col=y+1,pch=19))
renderPlot(plot(bachelors,col=candidate+3))
y<-candidate
x<-bachelors
#convert data to a data frame
data<-data.frame(y=factor(y),x)
head(data)
Radialsvm=svm(factor(y) ~ .,data=data,kernel="radial",cost=5,scale=F)
Radialsvm
#confusion matrix to check the accuracy
table(predicted=Radialsvm$fitted,actual=data$y)
#misclassification Rate
mean(Radialsvm$fitted!=data$y)*100 #8% misclassification rate
xgrid=expand.grid(X1=px1,X2=px2) #generating grid points
ygrid=predict(Radialsvm,newdata = xgrid)
renderPlot(plot(xgrid,col=as.numeric(ygrid),pch=20,cex=0.3)+points(x,col=y+1,pch=19))
renderPlot(plot(bachelors,col=candidate+3))
y<-candidate
x<-bachelors
#convert data to a data frame
data<-data.frame(y=factor(y),x)
head(data)
Radialsvm=svm(factor(y) ~ .,data=data,kernel="radial",cost=5,scale=F)
Radialsvm
#confusion matrix to check the accuracy
table(predicted=Radialsvm$fitted,actual=data$y)
#misclassification Rate
mean(Radialsvm$fitted!=data$y)*100 #8% misclassification rate
xgrid=expand.grid(X1=x,X2=y) #generating grid points
ygrid=predict(Radialsvm,newdata = xgrid)
renderPlot(plot(xgrid,col=as.numeric(ygrid),pch=20,cex=0.3)+points(x,col=y+1,pch=19))
renderPlot(plot(bachelors,col=candidate+3))
y<-candidate
x<-bachelors
#convert data to a data frame
data<-data.frame(y=factor(y),x)
head(data)
Radialsvm=svm(factor(y) ~ .,data=data,kernel="radial",cost=5,scale=F)
Radialsvm
#confusion matrix to check the accuracy
table(predicted=Radialsvm$fitted,actual=data$y)
#misclassification Rate
mean(Radialsvm$fitted!=data$y)*100 #8% misclassification rate
renderPlot(plot(bachelors,col=candidate+3))
renderPlot(plot(bachelors,col=candidate+3))
y<-candidate
x<-bachelors
#convert data to a data frame
data<-data.frame(y=factor(y),x)
head(data)
Radialsvm=svm(factor(y) ~ .,data=data,kernel="radial",cost=5,scale=F)
Radialsvm
#confusion matrix to check the accuracy
table(predicted=Radialsvm$fitted,actual=data$y)
#misclassification Rate
mean(Radialsvm$fitted!=data$y)*100 #8% misclassification rate
y<-candidate
x<-bachelors
data<-data.frame(y=factor(y),x)
head(data)
Radialsvm=svm(factor(y) ~ .,data=data,kernel="radial",cost=5,scale=F)
Radialsvm
table(predicted=Radialsvm$fitted,actual=data$y)
mean(Radialsvm$fitted!=data$y)*100 #8% misclassification rate
plot(bachelors,col=candidate+3)
candidate
results
df
require(data.world)
require(MASS)
require(ISLR)
require(dplyr)
require(ggplot2)
require(hexbin)
require(jsonlite)
require(shiny)
require(rsconnect)
require(knitr)
require(lubridate)
require(rmarkdown)
require(tidyr)
require(glmnet)
library(ggplot2)
library(class)
library(glmnet)
library(leaps)
library("e1071")
require(tree)
require(randomForest)
require(gbm)
knitr::opts_chunk$set(echo = TRUE)
require(data.world)
project <- "https://data.world/juandi/f-17-eda-project-4"
data.world::set_config(cfg_env("DW_API"))
electiondf <- data.world::query(
data.world::qry_sql("SELECT * FROM electiondata"),
dataset = project
)
attach(electiondf)
# Setting up the data
df = electiondf
result = df$candidate
df$candidate[df$candidate == "Trump"] <- 1
df$candidate[df$candidate == "Clinton"] <- 0
drops <- c("state")
df <- df[ , !(names(df) %in% drops)]
df$candidate = as.numeric(df$candidate)
df$candidate = as.numeric(df$votes)
df=data.frame(df, result)
tree.candidate=tree(result~.,df)
summary(tree.candidate)
renderPlot(plot(tree.candidate))
#text(tree.candidate,pretty=0))
set.seed(101)
train=sample(1:nrow(df),20)
rf.election=randomForest(result~.-candidate,data=df,subset=train)
rf.election
set.seed(101)
train1=sample(1:nrow(df),30)
rf.election1=randomForest(result~.-candidate,data=df,subset=train1)
rf.election1
set.seed(101)
train2=sample(1:nrow(df),45)
rf.election2=randomForest(result~.-candidate,data=df,subset=train2)
rf.election2
set.seed(101)
train=sample(1:nrow(df),45)
boost.election=gbm(result~.,data=df[train,],distribution="gaussian",n.trees=1000,shrinkage=0.001,interaction.depth=2)
renderPlot(summary(boost.election))
boost.election=gbm(result~.,data=df[train,],distribution="gaussian",n.trees=100,shrinkage=1,interaction.depth=3)
renderPlot(summary(boost.election))
boost.election=gbm(result~.,data=df[train,],distribution="gaussian",n.trees=10000,shrinkage=0.01,interaction.depth=4)
renderPlot(summary(boost.election))
renderPlot(plot(boost.election,i="graduates_degree"))
renderPlot(plot(boost.election,i="asian_american_pop"))
df
require(data.world)
require(MASS)
require(ISLR)
require(dplyr)
require(ggplot2)
require(hexbin)
require(jsonlite)
require(shiny)
require(rsconnect)
require(knitr)
require(lubridate)
require(rmarkdown)
require(tidyr)
require(glmnet)
library(ggplot2)
library(class)
library(glmnet)
library(leaps)
library("e1071")
require(tree)
require(randomForest)
require(gbm)
knitr::opts_chunk$set(echo = TRUE)
require(data.world)
project <- "https://data.world/juandi/f-17-eda-project-4"
data.world::set_config(cfg_env("DW_API"))
electiondf <- data.world::query(
data.world::qry_sql("SELECT * FROM electiondata"),
dataset = project
)
attach(electiondf)
# Setting up the data
df = electiondf
result = df$candidate
df$candidate[df$candidate == "Trump"] <- 1
df$candidate[df$candidate == "Clinton"] <- 0
drops <- c("state")
df <- df[ , !(names(df) %in% drops)]
df$candidate = as.numeric(df$candidate)
df$candidate = as.numeric(df$votes)
df=data.frame(df, result)
df
df$candidate[df$candidate == "Trump"] <- 1
df$candidate[df$candidate == "Clinton"] <- 0
df
require(data.world)
project <- "https://data.world/juandi/f-17-eda-project-4"
data.world::set_config(cfg_env("DW_API"))
electiondf <- data.world::query(
data.world::qry_sql("SELECT * FROM electiondata"),
dataset = project
)
attach(electiondf)
electiondf
df = electiondf
df
# Setting up the data
df = electiondf
result = df$candidate
df$candidate[df$candidate == "Trump"] <- 1
df$candidate[df$candidate == "Clinton"] <- 0
drops <- c("state")
df <- df[ , !(names(df) %in% drops)]
df$candidate = as.numeric(df$candidate)
df$candidate = as.numeric(df$votes)
df=data.frame(df, result)
df
require(data.world)
require(MASS)
require(ISLR)
require(dplyr)
require(ggplot2)
require(hexbin)
require(jsonlite)
require(shiny)
require(rsconnect)
require(knitr)
require(lubridate)
require(rmarkdown)
require(tidyr)
require(glmnet)
library(ggplot2)
library(class)
library(glmnet)
library(leaps)
library("e1071")
require(tree)
require(randomForest)
require(gbm)
knitr::opts_chunk$set(echo = TRUE)
require(data.world)
project <- "https://data.world/juandi/f-17-eda-project-4"
data.world::set_config(cfg_env("DW_API"))
electiondf <- data.world::query(
data.world::qry_sql("SELECT * FROM electiondata"),
dataset = project
)
attach(electiondf)
df = electiondf
result = df$candidate
df
results
result
# Setting up the data
df = electiondf
result = df$candidate
df$candidate[df$candidate == "Trump"] <- 1
df$candidate[df$candidate == "Clinton"] <- 0
drops <- c("state")
df <- df[ , !(names(df) %in% drops)]
df$candidate = as.numeric(df$candidate)
df$candidate = as.numeric(df$votes)
df=data.frame(df, result)
require(data.world)
require(MASS)
require(ISLR)
require(dplyr)
require(ggplot2)
require(hexbin)
require(jsonlite)
require(shiny)
require(rsconnect)
require(knitr)
require(lubridate)
require(rmarkdown)
require(tidyr)
require(glmnet)
library(ggplot2)
library(class)
library(glmnet)
library(leaps)
library("e1071")
require(tree)
require(randomForest)
require(gbm)
knitr::opts_chunk$set(echo = TRUE)
require(data.world)
project <- "https://data.world/juandi/f-17-eda-project-4"
data.world::set_config(cfg_env("DW_API"))
electiondf <- data.world::query(
data.world::qry_sql("SELECT * FROM electiondata"),
dataset = project
)
attach(electiondf)
df = electiondf
result = df$candidate
df$candidate[df$candidate == "Trump"] <- 1
df$candidate[df$candidate == "Clinton"] <- 0
df
drops <- c("state")
df <- df[ , !(names(df) %in% drops)]
df
# Setting up the data
df = electiondf
result = df$candidate
df$candidate[df$candidate == "Trump"] <- 1
df$candidate[df$candidate == "Clinton"] <- 0
drops <- c("state")
df <- df[ , !(names(df) %in% drops)]
df$candidate = as.numeric(df$candidate)
df=data.frame(df, result)
df
tree.candidate=tree(result~.,df)
summary(tree.candidate)
plot(tree.candidate)
#text(tree.candidate,pretty=0))
tree.candidate=tree(result~.,df)
summary(tree.candidate)
plot(tree.candidate)
text(tree.candidate,pretty=0)
tree.candidate=tree(result~.-candidate,df)
summary(tree.candidate)
plot(tree.candidate)
text(tree.candidate,pretty=0)
plot(bachelors,col=candidate+3)
y<-candidate
x<-bachelors
#convert data to a data frame
data<-data.frame(y=factor(y),x)
head(data)
Radialsvm=svm(factor(y) ~ .,data=data,kernel="radial",cost=5,scale=F)
Radialsvm
#confusion matrix to check the accuracy
table(predicted=Radialsvm$fitted,actual=data$y)
#misclassification Rate
mean(Radialsvm$fitted!=data$y)*100 #8% misclassification rate
plot(bachelors,col=candidate+3)
candidate
df$candidate[df$candidate == "Trump"] <- 1
df$candidate[df$candidate == "Clinton"] <- 0
df$candidate = as.numeric(df$candidate)
plot(bachelors,col=candidate+3)
y<-candidate
x<-bachelors
#convert data to a data frame
data<-data.frame(y=factor(y),x)
head(data)
Radialsvm=svm(factor(y) ~ .,data=data,kernel="radial",cost=5,scale=F)
Radialsvm
#confusion matrix to check the accuracy
table(predicted=Radialsvm$fitted,actual=data$y)
#misclassification Rate
mean(Radialsvm$fitted!=data$y)*100 #8% misclassification rate
plot(bachelors,col=candidate+3)
candidate
df$candidate[df$candidate == "Trump"] <- 1
df$candidate[df$candidate == "Clinton"] <- 0
df$candidate = as.numeric(df$candidate)
plot(bachelors,col=df$candidate+3)
y<-candidate
x<-bachelors
#convert data to a data frame
data<-data.frame(y=factor(y),x)
head(data)
Radialsvm=svm(factor(y) ~ .,data=data,kernel="radial",cost=5,scale=F)
Radialsvm
#confusion matrix to check the accuracy
table(predicted=Radialsvm$fitted,actual=data$y)
#misclassification Rate
mean(Radialsvm$fitted!=data$y)*100 #8% misclassification rate
tree.candidate=tree(result~.-candidate,df)
summary(tree.candidate)
plot(tree.candidate);text(tree.candidate,pretty=0))
tree.candidate=tree(result~.-candidate,df)
summary(tree.candidate)
plot(tree.candidate);text(tree.candidate,pretty=0)
tree.candidate=tree(result~.-candidate,df)
summary(tree.candidate)
renderPlot(
plot(tree.candidate)
text(tree.candidate,pretty=0)
)
tree.candidate=tree(result~.-candidate,df)
summary(tree.candidate)
renderPlot({
plot(tree.candidate)
text(tree.candidate,pretty=0)
})
